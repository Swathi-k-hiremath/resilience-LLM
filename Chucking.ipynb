{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"KER.txt\", \"r\")\n",
    "content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec87626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=128)\n",
    "chunked_docs = text_splitter.create_documents([content])\n",
    "len(chunked_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
    "                                                      model_kwargs={\"device\": \"cuda\"})'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c569d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''persist_directory = 'db'\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=instructor_embeddings)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d5e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'db'\n",
    "\n",
    "vectordb = Chroma.from_documents(chunked_docs, \n",
    "                                 embedding_function=embeddings,\n",
    "                                 persist_directory=persist_directory)\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Explain the concept of heat equity\"\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search_with_score(question,k=3)\n",
    "\n",
    "for result in docs:\n",
    "    print(\"\\n\")\n",
    "    print(result[1])\n",
    "    print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who are some vulnerable populations in Arizona \"\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search_with_score(question,k=3)\n",
    "\n",
    "for result in docs:\n",
    "    print(\"\\n\")\n",
    "    print(result[1])\n",
    "    print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072cd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the need for a Chief Heat Officer \"\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search_with_score(question,k=3)\n",
    "\n",
    "for result in docs:\n",
    "    print(\"\\n\")\n",
    "    print(result[1])\n",
    "    print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "[INST] <>\n",
    "Use the following context to Answer the question at the end. Do not use any other information. If you can't find the relevant information in the context, just say you don't have enough information to answer the question. Don't try to make up an answer.\n",
    "\n",
    "<>\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question} [/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "Chain_pdf = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    # retriever=db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'k': 5, 'score_threshold': 0.8})\n",
    "    # Similarity Search is the default way to retrieve documents relevant to a query, but we can use MMR by setting search_type = \"mmr\"\n",
    "    # k defines how many documents are returned; defaults to 4.\n",
    "    # score_threshold allows to set a minimum relevance for documents returned by the retriever, if we are using the \"similarity_score_threshold\" search type.\n",
    "    # return_source_documents=True, # Optional parameter, returns the source documents used to answer the question\n",
    "    retriever=vectordb.as_retriever(), # (search_kwargs={'k': 5, 'score_threshold': 0.8}),\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")\n",
    "query = \"Explain the concept of heat equity?\"\n",
    "result = Chain_pdf.invoke(query)\n",
    "print(fill(result['result'].strip(), width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea480c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a9cfef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee1707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ffa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2048, chunk_overlap=128)\n",
    "chunked_docs = text_splitter.create_documents([content])\n",
    "len(chunked_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"db2/\"\n",
    "big_chunks_retriever = Chroma.from_documents(chunked_docs, \n",
    "                                 embedding_function=embeddings,\n",
    "                                 persist_directory=persist_directory)\n",
    "big_chunks_retriever.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Explain the concept of heat equity\"\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search_with_score(question,k=3)\n",
    "\n",
    "for result in docs:\n",
    "    print(\"\\n\")\n",
    "    print(result[1])\n",
    "    print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e56a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who are some vulnerable populations in Arizona \"\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search_with_score(question,k=3)\n",
    "\n",
    "for result in docs:\n",
    "    print(\"\\n\")\n",
    "    print(result[1])\n",
    "    print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the need for a Chief Heat Officer \"\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search_with_score(question,k=3)\n",
    "\n",
    "for result in docs:\n",
    "    print(\"\\n\")\n",
    "    print(result[1])\n",
    "    print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c077dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
    "                                 chain_type=\"map_reduce\",\n",
    "                                 return_source_documents=True,\n",
    "                                 chain_type_kwargs=chain_type_kwargs,\n",
    "                                 retriever=big_chunks_retriever,\n",
    "                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88169fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When was the solar system formed?\"\n",
    "result = Chain_pdf.invoke(query)\n",
    "print(fill(result['result'].strip(), width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ffcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3572174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new package for PDFs \n",
    "# Untested \n",
    "# Needs Llama Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmsherpa.readers import LayoutPDFReader\n",
    "\n",
    "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "pdf_url = \"knowledgeexchangeforresilience.pdf\" # also allowed is a file path e.g. /home/downloads/xyz.pdf\n",
    "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "doc = pdf_reader.read_pdf(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446dad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.schema.base import Document\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex([])\n",
    "for chunk in doc.chunks():\n",
    "    index.insert(Document(text=chunk.to_context_text(), extra_info={}))\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Let's run one query\n",
    "response = query_engine.query(\"What is the need for a Chief Heat Officer \")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
